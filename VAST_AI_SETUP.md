# ğŸš€ IDM-VTON Vast.ai Kurulum Rehberi

Bu rehber, IDM-VTON Virtual Try-On sistemini Vast.ai Ã¼zerinde kurmak ve API olarak Ã§alÄ±ÅŸtÄ±rmak iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.

## ğŸ“‹ Gereksinimler

### Vast.ai Sunucu Gereksinimleri
- **GPU**: Tesla V100 veya daha Ã¼stÃ¼ (minimum 16GB VRAM)
- **RAM**: En az 32GB
- **Disk**: En az 50GB (model dosyalarÄ± iÃ§in)
- **CUDA**: 11.8 veya Ã¼stÃ¼

### Ã–nerilen Vast.ai KonfigÃ¼rasyonu
```bash
# Vast.ai CLI komutu (ÅŸablonunuzdan)
vastai create instance <OFFER_ID> \
    --image vastai/pytorch:@vastai-automatic-tag \
    --env '-p 8000:8000 -p 7860:7860' \
    --disk 50 \
    --ssh
```

## ğŸ¯ Kurulum AdÄ±mlarÄ±

### 1. Vast.ai Sunucuya BaÄŸlanma

```bash
# SSH ile baÄŸlanÄ±n
ssh root@YOUR_INSTANCE_IP -p YOUR_SSH_PORT
```

### 2. Proje DosyalarÄ±nÄ± YÃ¼kleme

```bash
# Workspace dizinine geÃ§in
cd /workspace

# Projenizi GitHub'dan klonlayÄ±n veya dosyalarÄ± upload edin
git clone https://github.com/yisol/IDM-VTON.git
cd IDM-VTON

# API dosyalarÄ±nÄ± ekleyin (bu rehberdeki dosyalarÄ±)
# vast_setup.sh, api_server.py, api_requirements.txt, etc.
```

### 3. Otomatik Kurulum

```bash
# Kurulum scriptini Ã§alÄ±ÅŸtÄ±rÄ±n
chmod +x vast_setup.sh
./vast_setup.sh
```

### 4. Manuel Kurulum (alternatif)

EÄŸer otomatik kurulum Ã§alÄ±ÅŸmazsa:

```bash
# Conda environment oluÅŸturun
conda env create -f environment.yaml
conda activate idm

# API baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kleyin
pip install -r api_requirements.txt

# Model dosyalarÄ±nÄ± indirin
mkdir -p ckpt/densepose ckpt/humanparsing ckpt/openpose/ckpts

# DensePose modeli
wget -O ckpt/densepose/model_final_162be9.pkl \
    "https://dl.fbaipublicfiles.com/detectron2/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl"

# Human parsing modelleri
wget -O ckpt/humanparsing/parsing_atr.onnx \
    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/ckpt/humanparsing/parsing_atr.onnx"
wget -O ckpt/humanparsing/parsing_lip.onnx \
    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/ckpt/humanparsing/parsing_lip.onnx"

# OpenPose modeli
wget -O ckpt/openpose/ckpts/body_pose_model.pth \
    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/ckpt/openpose/ckpts/body_pose_model.pth"

# IP-Adapter
git clone https://huggingface.co/h94/IP-Adapter
cp -r IP-Adapter/sdxl_models/* ckpt/ip_adapter/
cp -r IP-Adapter/models/image_encoder/* ckpt/image_encoder/
```

## ğŸŒ Servisleri BaÅŸlatma

### Sadece API Server (Ã–nerilen)

```bash
python api_server.py
```

API ÅŸu adreste eriÅŸilebilir olacak:
- **API DokÃ¼mantasyonu**: `http://YOUR_INSTANCE_IP:8000/docs`
- **Health Check**: `http://YOUR_INSTANCE_IP:8000/health`

### Sadece Gradio Interface

```bash
python gradio_demo/app.py
```

Web interface: `http://YOUR_INSTANCE_IP:7860`

### Her Ä°kisi Birden

```bash
# Terminal 1
python gradio_demo/app.py &

# Terminal 2
python api_server.py
```

## ğŸ”§ API KullanÄ±mÄ±

### Python Client Ã–rneÄŸi

```python
import requests
import base64

# API endpoint
api_url = "http://YOUR_INSTANCE_IP:8000"

# Dosya upload ile
files = {
    'human_image': open('human.jpg', 'rb'),
    'garment_image': open('garment.jpg', 'rb')
}
data = {
    'garment_description': 'red t-shirt',
    'auto_mask': True,
    'denoise_steps': 30,
    'seed': 42
}

response = requests.post(f"{api_url}/try-on", files=files, data=data)
result = response.json()

if result['success']:
    # Result image'Ä± kaydet
    with open('result.png', 'wb') as f:
        f.write(base64.b64decode(result['result_image']))
```

### cURL Ã–rneÄŸi

```bash
curl -X POST "http://YOUR_INSTANCE_IP:8000/try-on" \
     -F "human_image=@human.jpg" \
     -F "garment_image=@garment.jpg" \
     -F "garment_description=red t-shirt" \
     -F "auto_mask=true" \
     -F "denoise_steps=30" \
     -F "seed=42"
```

## ğŸ“Š API Endpoints

### GET `/health`
Sunucu durumunu kontrol eder.

### POST `/try-on`
Dosya upload ile virtual try-on.

**Parametreler:**
- `human_image`: Ä°nsan fotoÄŸrafÄ± (file)
- `garment_image`: Giysi fotoÄŸrafÄ± (file)
- `garment_description`: Giysi aÃ§Ä±klamasÄ± (string)
- `auto_mask`: Otomatik mask kullan (boolean, default: true)
- `auto_crop`: Otomatik crop kullan (boolean, default: false)
- `denoise_steps`: Denoising adÄ±mlarÄ± (int, 20-40, default: 30)
- `seed`: Random seed (int, optional)

### POST `/try-on-base64`
Base64 encoded images ile virtual try-on.

### POST `/load-models`
Modelleri GPU'ya yÃ¼kler.

### POST `/unload-models`
Modelleri GPU'dan kaldÄ±rÄ±r (memory tasarrufu iÃ§in).

## ğŸ³ Docker ile Kurulum (Alternatif)

```bash
# Docker image build et
docker build -t idm-vton .

# Sadece API Ã§alÄ±ÅŸtÄ±r
docker run --gpus all -p 8000:8000 -e SERVICE_MODE=api idm-vton

# Gradio interface Ã§alÄ±ÅŸtÄ±r
docker run --gpus all -p 7860:7860 -e SERVICE_MODE=gradio idm-vton

# Her ikisi birden Ã§alÄ±ÅŸtÄ±r
docker run --gpus all -p 8000:8000 -p 7860:7860 -e SERVICE_MODE=both idm-vton
```

### Docker Compose ile

```bash
# Sadece API
docker-compose up idm-vton-api

# Sadece Gradio
docker-compose --profile gradio-only up

# Her ikisi birden
docker-compose --profile both up
```

## ğŸ”¥ Performans Optimizasyonu

### GPU Memory YÃ¶netimi

```python
# Modelleri ihtiyaÃ§ halinde yÃ¼kle/kaldÄ±r
requests.post(f"{api_url}/load-models")    # GPU'ya yÃ¼kle
requests.post(f"{api_url}/unload-models")  # CPU'ya taÅŸÄ±
```

### Batch Ä°ÅŸleme

```python
# Ã‡oklu istekler iÃ§in modelleri GPU'da tutun
requests.post(f"{api_url}/load-models")

for image_pair in image_pairs:
    result = requests.post(f"{api_url}/try-on", ...)
    # Process result

# Ä°ÅŸ bitince GPU'yu temizle
requests.post(f"{api_url}/unload-models")
```

## ğŸ› ï¸ Troubleshooting

### YaygÄ±n Problemler

**Problem**: CUDA out of memory
```bash
# Ã‡Ã¶zÃ¼m: Modelleri CPU'ya taÅŸÄ±
curl -X POST "http://localhost:8000/unload-models"
```

**Problem**: Model dosyalarÄ± eksik
```bash
# Ã‡Ã¶zÃ¼m: Setup scriptini tekrar Ã§alÄ±ÅŸtÄ±r
./vast_setup.sh
```

**Problem**: Port eriÅŸim sorunu
```bash
# Vast.ai port konfigÃ¼rasyonunu kontrol et
# Instance ayarlarÄ±ndan 8000 ve 7860 portlarÄ±nÄ± aÃ§Ä±k olduÄŸundan emin ol
```

### Log Kontrol

```bash
# API logs
tail -f api.log

# Gradio logs
tail -f gradio.log

# System logs
journalctl -f
```

## ğŸ“ˆ Monitoring

### GPU KullanÄ±mÄ±

```bash
# GPU status
nvidia-smi

# SÃ¼rekli monitoring
watch -n 1 nvidia-smi
```

### API PerformansÄ±

```bash
# Health check
curl http://localhost:8000/health

# Detailed status
curl http://localhost:8000/health | jq
```

## ğŸ”’ GÃ¼venlik

### Production iÃ§in Ã–neriler

1. **CORS ayarlarÄ±** - `api_server.py` dosyasÄ±nda `allow_origins` kÄ±smÄ±nÄ± dÃ¼zenleyin
2. **Rate limiting** ekleyin
3. **API key authentication** ekleyin
4. **HTTPS** kullanÄ±n
### Firewall

```bash
# Sadece gerekli portlarÄ± aÃ§
ufw allow 8000  # API
ufw allow 7860  # Gradio
ufw enable
```

## ğŸ“ Destek

### Test Scripti

```bash
# API'yi test et
python test_api.py
```

### YararlÄ± Komutlar

```bash
# Disk kullanÄ±mÄ±
df -h

# Memory kullanÄ±mÄ±
free -h

# Process listesi
ps aux | grep python

# Port kontrolÃ¼
netstat -tlnp | grep :8000
```

## âœ… BaÅŸarÄ± KontrolÃ¼

Kurulum baÅŸarÄ±lÄ± ise:
1. âœ… `http://YOUR_INSTANCE_IP:8000/health` OK dÃ¶ner
2. âœ… `http://YOUR_INSTANCE_IP:8000/docs` API dokÃ¼mantasyonunu gÃ¶sterir
3. âœ… Test istekleri baÅŸarÄ±lÄ± sonuÃ§ dÃ¶ner

---

## ğŸ‰ Tebrikler!

IDM-VTON sisteminiz artÄ±k Vast.ai Ã¼zerinde Ã§alÄ±ÅŸÄ±yor ve API olarak kullanÄ±ma hazÄ±r!

### Sonraki AdÄ±mlar
- Kendi uygulamanÄ±zdan API'yi kullanmaya baÅŸlayÄ±n
- Performans optimizasyonlarÄ± yapÄ±n
- Ä°htiyaÃ§larÄ±nÄ±za gÃ¶re API'yi geniÅŸletin